{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Mahima Chowdary Maddineni, October 28, 2022* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super-resolution refers to improving the resolution of an image. Optimization-based super-resolution methods are primarily focused on minimizing the mean squared error. One of the methods is by using autoencoders. An autoencoder is just an unsupervised neural network that, by design, learns how to compress and reconstruct data with the least amount of data loss. However, optimization-based super-resolution often lacks high-frequency details and fails to match the accuracy expected at the higher resolution. GANs use a perceptual loss function which consists of an adversarial loss and a content loss which helps in producing better output. In this project, I would like to build these two models and compare them.\n",
    "\n",
    "**Dataset**:\n",
    "\n",
    "[Large-scale CelebFaces Attributes (CelebA) Dataset.](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
    "It has over 202,599 number of face images of various celebrities.\n",
    "\n",
    "[Berkeley Segmentation Dataset.](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/)The dataset is composed of a large variety of images ranging from natural images to object-specific such as plants, people, food etc.\n",
    "\n",
    "Planned methods:\n",
    "* Create training data by adding noise to it\n",
    "* Building models\n",
    "* Train the models by comparing it to the loss\n",
    "* Testing the models\n",
    "* Output visulization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CelebA dataset and Berkley segmentation dataset are image datasets. These images are preprocessed and resolution is reduced to get low resolution images. While training these low resolution images loss is compared to high resolution images, and model is trained to produce hr images.\n",
    "\n",
    "GAN produces higher-resolution images by combining a deep network with an opponent network. A high-resolution image (HR) is downsampled to a low-resolution image during training (LR). A GAN generator converts low-resolution photos to high-resolution images (SR). We employ a discriminator and backpropagate the GAN loss to separate the HR pictures to train the discriminator and generator.\n",
    "\n",
    "Prior to training, autoencoders add some white noise to the image. They compare the mistake to the original image while training.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Expected date | Milestone |\n",
    "| -:| -: |\n",
    "|November  6| Data Collection and preprocessing |\n",
    "|November 13| Training |\n",
    "|November 20| Testing and evaluation|\n",
    "|November 27| Output presentation |\n",
    "|December  4| Report drafting |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High resolution images can be generated from the low resolution images.\n",
    "- GAN can perform better than Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I anticipate learning about GANs and autoencoders.\n",
    "- Debugging the code after building GANs and autoencoders will be difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/pdf/1609.04802v5.pdf),Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi, CVPR 2017.\n",
    "* [Unsupervised Real Image Super-Resolution via Generative Variational AutoEncoder](https://arxiv.org/pdf/2004.12811v1.pdf), Zhi-Song Liu, Wan-Chi Siu, Li-Wen Wang, Chu-Tak Li, Marie-Paule Cani, Yui-Lam Chan.\n",
    "* [Comprehensive Introduction to Autoencoders](https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368)\n",
    "* [Introduction to Turing Learning and GANs](https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
